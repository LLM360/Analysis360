# Analysis360: Analyze LLMs in 360 degrees
<div align="center">
   <img src="./docs/imgs/llm360-icon.webp"><br><br>
</div>

-----------------
<p align="center">
   <a href="https://github.com/LLM360/Analysis360/blob/dev/LICENSE"><img src="https://img.shields.io/badge/license-Apache%202.0-blue.svg" alt="license"></a>
</p>
<p align="center">
  <a href="">Blogpost[Amber]</a> •
  <a href="">wandb dashboard[Amber]</a> •
  <a href="">Blogpost[CrystalCoder]</a> •
  <a href="">wandb dashboard[CrystalCoder]</a> •
  <a href="">Publication</a>
</p>
Welcome to LLM360! 

This repo contains all the code that we used for model evaluation and analysis.

We use this repo as the single source of truth for all evaluation metrics and provide in-depth analysis from many different angles.

## Our Approach
There are a lot of metrics included, we not only measure models' ability by running common evaluation benchmarks like MMLU, Hellaswag but also dive deep into other areas like toxicity and bias. 
Moreover, to better observe and understand how our models develop and evolve over the training process, we sampled a few checkpoints from our model pool with fixed intervals for trend analysis.
All the results are published on our wandb project page, we will keep updating it as more metrics and evaluations are coming out, stay tuned!

## List of Analysis
introduction
### Common LM eval metrics:
- link to code
- link to wandb
### Additional model characteristics
#### toxigen
#### bold
#### more to come
