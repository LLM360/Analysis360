{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WMDP Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is an example command to evaluate [LLM360/CrystalChat](https://huggingface.co/LLM360/CrystalChat) on [WMDP](https://www.wmdp.ai/) with ``lm-eval``: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-06:18:54:40,360 INFO     [__main__.py:279] Verbosity set to INFO\n",
      "2024-10-06:18:54:41,939 INFO     [__init__.py:491] `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.\n",
      "2024-10-06:18:54:47,349 INFO     [__main__.py:376] Selected Tasks: ['wmdp_bio', 'wmdp_chem', 'wmdp_cyber']\n",
      "2024-10-06:18:54:47,356 INFO     [evaluator.py:161] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-10-06:18:54:47,356 INFO     [evaluator.py:198] Initializing hf model, with arguments: {'pretrained': 'LLM360/CrystalChat', 'trust_remote_code': True}\n",
      "2024-10-06:18:54:47,477 INFO     [huggingface.py:130] Using device 'cuda'\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2024-10-06:18:54:48,022 INFO     [huggingface.py:366] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:01<00:00,  1.06it/s]\n",
      "2024-10-06:18:54:52,120 WARNING  [task.py:338] [Task: wmdp_bio] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2024-10-06:18:54:52,120 WARNING  [task.py:338] [Task: wmdp_bio] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2024-10-06:18:54:53,548 WARNING  [task.py:338] [Task: wmdp_chem] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2024-10-06:18:54:53,548 WARNING  [task.py:338] [Task: wmdp_chem] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2024-10-06:18:54:54,647 WARNING  [task.py:338] [Task: wmdp_cyber] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2024-10-06:18:54:54,647 WARNING  [task.py:338] [Task: wmdp_cyber] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2024-10-06:18:54:54,696 INFO     [evaluator.py:279] Setting fewshot random generator seed to 1234\n",
      "2024-10-06:18:54:54,696 INFO     [evaluator.py:279] Setting fewshot random generator seed to 1234\n",
      "2024-10-06:18:54:54,696 INFO     [evaluator.py:279] Setting fewshot random generator seed to 1234\n",
      "2024-10-06:18:54:54,696 WARNING  [model.py:422] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.\n",
      "2024-10-06:18:54:54,698 INFO     [task.py:428] Building contexts for wmdp_cyber on rank 0...\n",
      "100%|██████████████████████████████████████| 1987/1987 [00:02<00:00, 967.82it/s]\n",
      "2024-10-06:18:54:56,802 INFO     [task.py:428] Building contexts for wmdp_chem on rank 0...\n",
      "100%|████████████████████████████████████████| 408/408 [00:00<00:00, 964.02it/s]\n",
      "2024-10-06:18:54:57,236 INFO     [task.py:428] Building contexts for wmdp_bio on rank 0...\n",
      "100%|██████████████████████████████████████| 1273/1273 [00:01<00:00, 968.78it/s]\n",
      "2024-10-06:18:54:58,581 INFO     [evaluator.py:485] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|████| 14672/14672 [02:03<00:00, 118.33it/s]\n",
      "2024-10-06:18:57:14,429 INFO     [evaluation_tracker.py:269] Output path not provided, skipping saving results aggregated\n",
      "hf (pretrained=LLM360/CrystalChat,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 16\n",
      "|  Tasks   |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
      "|----------|------:|------|-----:|------|---|-----:|---|-----:|\n",
      "|wmdp_bio  |      1|none  |     0|acc   |↑  |0.5915|±  |0.0138|\n",
      "|wmdp_chem |      1|none  |     0|acc   |↑  |0.3946|±  |0.0242|\n",
      "|wmdp_cyber|      1|none  |     0|acc   |↑  |0.3936|±  |0.0110|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!lm-eval --model hf \\\n",
    "    --model_args pretrained=LLM360/CrystalChat,trust_remote_code=True,dtype=float16 \\\n",
    "    --tasks wmdp_bio,wmdp_cyber,wmdp_chem \\\n",
    "    --batch_size=16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unlearn360",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
